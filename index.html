<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<!-- saved from url=(0055)https://qmul-survface.github.io/QMUL-SurvFace/index.htm -->
<html xmlns="http://www.w3.org/1999/xhtml">
   <head>
      <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
      <title>QMUL-OpenLogo</title>
      <meta name="description" content="For enabling a larger scale logo detection model exploration, and collect a large 
					number of logo classes for simulating the real-world logo detection at scales,
					we propose to re-exploit the existing logo detection datasets.
         To maximise the context richness of logo images,
we assemble 7 existing publicly accessible logo detection datasets (Table \ref{tab:dataset}) sourced from diverse domains
to establish the OpenLogo evaluation benchmark. 
All these datasets together present significant 
logo variations and therefore represent the truthful logo detection challenge
as encountered in real-world unconstrained deployments. Result in a OpenLogo dataset with 27083 images of 352 classes.">
      <meta name="keywords" content="QMUL; 
         QMUL OpenLogo Dataset; OpenLogo;
         logo recognition; logo detection; 
         benchmark; computer vision;">
      <!-- Fonts and stuff -->
      <link href="./CSS/project.css" rel="stylesheet">
      <link href="./CSS/iconize.css" rel="stylesheet">
      <link href="./css/" rel="shortcut icon">
      <script type="text/javascript" async="" src="./QMUL-SurvFace_files/ga.js"></script>
      <link href="http://twitter.github.com/bootstrap/assets/ico/apple-touch-icon-144-precomposed.png" rel="apple-touch-icon-precomposed" sizes="144x144">
      <link href="http://twitter.github.com/bootstrap/assets/ico/apple-touch-icon-114-precomposed.png" rel="apple-touch-icon-precomposed" sizes="114x114">
      <link href="http://twitter.github.com/bootstrap/assets/ico/apple-touch-icon-72-precomposed.png" rel="apple-touch-icon-precomposed" sizes="72x72">
      <link href="http://twitter.github.com/bootstrap/assets/ico/apple-touch-icon-57-precomposed.png" rel="apple-touch-icon-precomposed">
   </head>
   <body>
      <div id="content">
         <div id="content-inner">
            <div class="section head">
               <p>
               <h1 id="OpenLogo Dataset">QMUL-OpenLogo Dataset</h1>
               </p>
               <div class="affiliations">
                  <p><a href="http://www.eecs.qmul.ac.uk/~hs308/">Hang Su</a> &nbsp; &nbsp; &nbsp; &nbsp;
                     <a href="http://www.eecs.qmul.ac.uk/~xiatian/">Xiatian Zhu</a> &nbsp; &nbsp; &nbsp; &nbsp;
                     <a href="http://www.eecs.qmul.ac.uk/~sgg/">Shaogang Gong</a>
                  <p><a href="http://vision.eecs.qmul.ac.uk/">Computer Vision Group,  </a >
                     <a href="http://www.eecs.qmul.ac.uk/">School of Electronic Engineering and Computer Science,  </a >
                     <a href="http://www.qmul.ac.uk/">Queen Mary University of London</a >
               </div>
               <ul id="tabs">
                  <li><a href="https://qmul-survface.github.io/index.html" name="#tab1" id="current">Home</a></li>
                  <!-- <li><a href="https://qmul-survface.github.io/protocols.html" name="#tab2">Protocols</a></li>-->
                  <!-- <li><a href="https://qmul-survface.github.io/benchmark.html" name="#tab3">Leaderboard</a></li>-->
               </ul>
            </div>
            <center><img style="width: 95%;" src="./scc/img_combined3.jpg" alt="QMUL OpenLogo"></center>
            <h2 id="description">Description</h2>
            <p>For enabling a larger scale logo detection model exploration, and collect a large 
					number of logo classes for simulating the real-world logo detection at scales,
					we propose to re-exploit the existing logo detection datasets.
         To maximise the context richness of logo images,
we assemble 7 existing publicly accessible logo detection datasets (Table \ref{tab:dataset}) sourced from diverse domains
to establish the OpenLogo evaluation benchmark. 
All these datasets together present significant 
logo variations and therefore represent the truthful logo detection challenge
as encountered in real-world unconstrained deployments. Result in a OpenLogo dataset with 27083 images of 352 classes.
            </p>
	      
	    <h2 id="description">Statistic</h2>
            <p>
		<div class="tab">
                  <table align="center" width="100%" style="margin: 0px auto;" class="justify" cellpadding="0" cellspacing="0">
                     <thead>
                        <tr>
                           <th>Algorithm</th>
                           <th>Publication</th>
                           <th>TPIR@FPIR=30%</th>
                           <th>TPIR@FPIR=20%</th>
                           <th>TPIR@FPIR=10%</th>
                           <th>AUC</th>
                        </tr>
                     </thead>
                     <tbody>
                        <tr>
                           <td><a href="https://pdfs.semanticscholar.org/8774/e206564df3bf9050f8c2be6b434cc2469c5b.pdf?_ga=2.147452215.187194200.1528491351-695318045.1528491351"><strong>CentreFace</strong></a></td>
                           <td>ECCV 2016</td>
                           <td>24.5%</td>
                           <td>19.6%</td>
                           <td>13.2%</td>
                           <td>33.7%</td>
                        </tr>
                        <tr>
                           <td><a href="http://openaccess.thecvf.com/content_cvpr_2017/papers/Liu_SphereFace_Deep_Hypersphere_CVPR_2017_paper.pdf"><strong>SphereFace</strong></a></td>
                           <td>CVPR 2017</td>
                           <td>15.8%</td>
                           <td>11.8%</td>
                           <td>6.8%</td>
                           <td>21.5%</td>
                        </tr>
                        <tr>
                           <td><a href="https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Schroff_FaceNet_A_Unified_2015_CVPR_paper.pdf"><strong>FaceNet<strong></a></td>
                           <td>CVPR 2015</td>
                           <td>12.0%</td>
                           <td>7.5%</td>
                           <td>3.9%</td>
                           <td>18.6%</td>
                        </tr>
                        <tr>
                           <td><a href="http://papers.nips.cc/paper/5416-deep-learning-face-representation-by-joint-identification-verification.pdf"><strong>DeepID2</strong></a></td>
                           <td>NIPS 2014</td>
                           <td>12.0%</td>
                           <td>7.5%</td>
                           <td>2.8%</td>
                           <td>18.7%</td>
                        </tr>
                        <tr>
                           <td><a href="http://cis.csuohio.edu/~sschung/CIS660/DeepFaceRecognition_parkhi15.pdf"><strong>VggFace</strong></a></td>
                           <td>BMVC 2015</td>
                           <td>6.5%</td>
                           <td>4.8%</td>
                           <td>2.5%</td>
                           <td>9.6%</td>
                        </tr>
                     </tbody>
                  </table>
            </p>
	      
            <h2 id="news">News</h2>
            <p>
            <ul>
               <li><strong>July 03, 2018:</strong> Dataset released. </li>
            </ul>
            </p>
            <h2 id="download">Download</h2>
            <p>QMUL-OpenLogo Dataset ( MB): 
               [<a href="https://drive.google.com/open?id=13ch6BPaexlKt8gXB_I8aX7p1G3yPm2Bl" target="_blank">Google Drive</a>] 
               <!-- [<a href="https://pan.baidu.com/s/1O55042SMxLYqBWdGGQ_4_g" target="_blank">Baidu Cloud</a>]-->
            </p>
            <h2 id="citation">Citation</h2>
            <pre>
	    	<em>Open Logo Detection Challenge.</em>
		Hang Su, Xiatian Zhu and Shaogang Gong.
		<!-- arXiv:1804.09691, 2018. <a href="QMUL-SurvFace_bibtex.html">Bibtex</a> <a href="https://arxiv.org/pdf/1804.09691.pdf">Paper</a>-->
	    </pre>
            <h2 id="Related Datasets">Related Datasets</h2>
            <p>We list below the related datasets.</a></p>
            <ul>
               <li><a href="http://www.multimedia-computing.de/flickrlogos/">FlickrLogo-32</a>
               </li>
               <li><a href="http://image.ntua.gr/iva/datasets/flickr_logos/">Flickr Logo 27</a>
               </li>
	       <li><a href="http://www.ivl.disco.unimib.it/activities/logo-recognition/">Logo32plus</a>
               </li>
	       <li><a href="http://www-sop.inria.fr/members/Alexis.Joly/BelgaLogos/BelgaLogos.html">BelgaLogos</a>
               </li>	       
	       <li><a href="http://www.eecs.qmul.ac.uk/~hs308/WebLogo-2M.html/">WebLogo-2M</a>
               </li>
	       <li><a href="https://www.iosb.fraunhofer.de/servlet/is/78045/">Logos-in-the-wild</a>
               </li>
	       <li><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8237781">SportsLogo</a>
               </li>
            </ul>
            <h2 id="Licence">Licence</h2>
            <p>Please notice that the QMUL-OpenLogo Dataset is made available for academic research purpose only. 
               All the images were collected from the existing logo detection datasets, 
               and the copyright belongs to the original owners. 
            </p>
            <h2 id="contact">Contact</h2>
            <p>Please feel free to send any questions and/or comments to Hang Su at <strong>hang.su@qmul.ac.uk</strong></p>
            </div>
         
      </div>
   </body>
</html>
